{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ee5efae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28220e4c",
   "metadata": {},
   "source": [
    "# Getting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ad7e6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose mi\n"
     ]
    }
   ],
   "source": [
    "shakespeares_work = '/Users/avikram/Documents/Deep Learning Masterclass/06-NLP-and-Text-Data/shakespeare.txt'\n",
    "\n",
    "with open(shakespeares_work, 'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "print(text [0 : 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da517aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unique characters\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "len(vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7e5a71",
   "metadata": {},
   "source": [
    "# Text Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "891a785a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every character is assigned a numeric index\n",
    "\n",
    "char_to_index = {\n",
    "    char: ind for ind, char in enumerate(vocab)\n",
    "}\n",
    "\n",
    "char_to_index['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31db0b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Every index is assigned a character\n",
    "\n",
    "ind_to_char = np.array(vocab)\n",
    "\n",
    "ind_to_char[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd108536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64]\n"
     ]
    }
   ],
   "source": [
    "encoded_text = np.array([char_to_index[c] for c in text])\n",
    "encoded_text.shape\n",
    "\n",
    "print(encoded_text[0 : 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d31193e",
   "metadata": {},
   "source": [
    "# Creating Batches\n",
    "\n",
    "- Sequence length depends a lot on the kind of data you have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b83f361e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45005"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_len = 120\n",
    "total_sequences = len(text) // (sequence_len + 1)\n",
    "total_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fcce8f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)\n",
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec622995",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = char_dataset.batch(sequence_len + 1, drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0ee5840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequence_targets(seq):\n",
    "    \n",
    "    input_text = seq[ : -1] # Hello my nam\n",
    "    target_text = seq[1 : ] # ello my name\n",
    "    \n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1d229e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(create_sequence_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9301c291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But\n",
      "\n",
      "\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But \n"
     ]
    }
   ],
   "source": [
    "for input_text, target_text in dataset.take(1):\n",
    "    \n",
    "    #Printing input sequence\n",
    "    print(input_text.numpy())\n",
    "    print(''.join(ind_to_char[input_text.numpy()]))\n",
    "    \n",
    "    print('\\n')\n",
    "    \n",
    "    #Printing target sequence\n",
    "    print(target_text.numpy())\n",
    "    print(''.join(ind_to_char[target_text.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d4be0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2bc26f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "buffer_size = 10000\n",
    "\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45502734",
   "metadata": {},
   "source": [
    "# Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a65cc9af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocab)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "17f7a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 64 # something of same scale of vocab size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea17d778",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_neurons = 1026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bbbdfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46ab5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y, predictions):\n",
    "    \n",
    "    return sparse_categorical_crossentropy(y, predictions, from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "326fd561",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2cd76aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocab_size, embed_dim, rnn_neurons, batch_size):\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Embedding(vocab_size, embed_dim, batch_input_shape=[batch_size, None]))\n",
    "    \n",
    "    model.add(\n",
    "        GRU(\n",
    "        rnn_neurons, \n",
    "        return_sequences=True, \n",
    "        stateful=True, \n",
    "        recurrent_initializer='glorot_uniform'\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    model.add(Dense(vocab_size))\n",
    "    \n",
    "    model.compile('adam', loss=sparse_cat_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b8ddd77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 64)           5376      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 1026)         3361176   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 84)           86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e732cb",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7776722a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    \n",
    "    example_batch_predictions = model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95d118e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5, 1), dtype=int64, numpy=\n",
       "array([[82],\n",
       "       [34],\n",
       "       [17],\n",
       "       [83],\n",
       "       [71]])>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "361cba71",
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89f2c71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82, 34, 17, 83, 71, 60, 37, 77, 83, 46, 34, 17, 53, 60, 45, 74, 60,\n",
       "       32, 41, 33,  9, 50, 58, 36, 75, 42, 39, 45, 16, 50, 63, 79, 33, 18,\n",
       "        6, 81, 79, 79, 50,  6, 11,  9, 12, 67, 26, 17, 65, 33, 17, 33, 80,\n",
       "       68, 55, 71, 80, 11, 60, 21, 15, 64, 75, 37, 20,  4, 35, 80, 60,  5,\n",
       "       79, 76, 21, 58, 54, 47, 12, 77, 19, 64, 48, 33, 22, 23, 28,  2, 31,\n",
       "       20,  4, 20,  3, 38, 25, 44, 54, 12, 40, 37, 26, 24, 29, 15, 54,  5,\n",
       "       23, 65, 40, 79, 68, 30, 11, 30,  0, 39, 41, 68, 27,  4,  8, 18, 22,\n",
       "       81])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f9b769cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7aef2c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 64)             5376      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1026)           3361176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 84)             86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Loading up model\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "model = create_model(vocab_size, embed_dim, rnn_neurons, batch_size=1)\n",
    "model.load_weights('/Users/avikram/Documents/Deep Learning Masterclass/06-NLP-and-Text-Data/shakespeare_gen.h5')\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ea6a32eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, start_seed, gen_size=500, temp=1.0):\n",
    "    \n",
    "    num_generate = gen_size\n",
    "    \n",
    "    input_eval = [char_to_index[s] for s in start_seed]\n",
    "    \n",
    "    input_eval = tf.expand_dims(input_eval, 0)\n",
    "    \n",
    "    text_generated = []\n",
    "    \n",
    "    temperature = temp\n",
    "    \n",
    "    model.reset_states()\n",
    "    \n",
    "    for i in range (num_generate):\n",
    "        \n",
    "        predictions = model(input_eval)\n",
    "        \n",
    "        predictions = tf.squeeze(predictions, 0)\n",
    "        \n",
    "        predictions = predictions/temperature\n",
    "        \n",
    "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
    "        \n",
    "        input_eval = tf.expand_dims([predicted_id], 0)\n",
    "        \n",
    "        text_generated.append(ind_to_char[predicted_id])\n",
    "            \n",
    "    return (start_seed + \"\".join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1d829ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JULIETHEN. Fool'st thou mear the child?\n",
      "  TUTOR. If I may sing your Grace; but what of him?\n",
      "    My slips of stern incense that ghing leads\n",
      "    Th' ad honour ot to keep with him.\n",
      "  OTHELLO.                    For this experied your babb,\n",
      "  \n",
      "    What doth he thrust it? Let us shine to beat thee:\n",
      "    Place is your chafeth of fair creatures.\n",
      "  SATURNINUS. Even prither in emperial lov'd that would not\n",
      "    Lomeable break indeed. Heper is sometimes.\n",
      "    Am not amiss.\n",
      "  FLUELLEN. We are of your Grace.\n",
      "  PETRUCHIO. Signior Baptista that hath done no unclean broils\n",
      "    to live o' th' opinion of heaven and his wife's\n",
      "    a king's clearness, graspa show living, the beggar.\n",
      "    But I had rather had so double deep that thus pass'd by my friend all which her husband have\n",
      "    Here in the most offender. Beredia, what are they?\n",
      "  ROSALINE. In faith, Sir Pardon painted, 'twere a good great; if I lack since\n",
      "    it is as half a cardinal'd office, worm, to whom I lie. Can you remain\n",
      "    that I am not above accorm\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model, \"JULIET\", gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f8e4de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
