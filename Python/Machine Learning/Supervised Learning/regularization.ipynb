{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Overfitting vs Underfitting\n",
    "\n",
    "## Overfitting\n",
    "\n",
    "When the model passes through all points, leading to 0 error on training set,\n",
    "but high error on unseen data.\n",
    "\n",
    "## Underfitting\n",
    "\n",
    "Model doesn't pass through most of the points, thus leading to high error\n",
    "metrics.\n",
    "\n",
    "\"A good model is the one whose error decreases with increase in complexity\"\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Regularization\n",
    "\n",
    "Reduces model overfitting and variance.\n",
    "\n",
    "## Three Types\n",
    "\n",
    "* L1 Regularization - LASSO Regression\n",
    "* L2 Regularization - Ridge Regression\n",
    "* L1 & L2 Regularization - Elastic Net\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Feature Scaling\n",
    "\n",
    "It is used when we have features that are in different units.\n",
    "Fitting is only to be done on training data\n",
    "\n",
    "## Process\n",
    "\n",
    "* Perform train-test split\n",
    "* Fit to training feature data\n",
    "* Transform training feature data\n",
    "* Transform test feature data\n",
    "\n",
    "DO NOT SCALE LABEL DATA.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cross Validation\n",
    "\n",
    "An advanced way to split data into training and testing sets.\n",
    "\n",
    "Train-validation-test split with K-fold is the best way to cross validate.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, SCORERS\n",
    "from sklearn.linear_model import Ridge, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df = pd.read_csv('~/Documents/Data Science Masterclass/DATA/Advertising.csv')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "X = df.drop('sales', axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "y = df['sales']"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "polynomial_converter = PolynomialFeatures(degree=3, include_bias=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "polynomial_features = polynomial_converter.fit_transform(X)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(polynomial_features, \n",
    "    y, test_size=0.3, random_state=101)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "scaler = StandardScaler()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "scaler.fit(X_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "X_train = scaler.transform(X_train)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "X_test = scaler.transform(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Ridge Regression\n",
    "\n",
    "A regularization technique that reduces potential over-fitting to the training\n",
    "data by adding a penalty term to the error that is based on the squared value\n",
    "of the coefficients.\n",
    "\n",
    "* Error = RSS + µß^2\n",
    "Note: µ is referred to as å in sklearn function calls.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "ridge_model = Ridge(alpha=10)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "ridge_model.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Ridge(alpha=10)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "y_hat = ridge_model.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, y_hat))\n",
    "RMSE"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8946386461319685"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "ridge_cv_model = RidgeCV(alphas=(0.1, 1, 10), scoring='neg_mean_absolute_error')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "ridge_cv_model.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "RidgeCV(alphas=array([ 0.1,  1. , 10. ]), scoring='neg_mean_absolute_error')"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "ridge_cv_model.alpha_ # Get best alpha value"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "y_hat = ridge_cv_model.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, y_hat))\n",
    "RMSE"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6180719926924644"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Lasso Regression\n",
    "\n",
    "Can yield same error (or better) than ridge regression, but does so by making\n",
    "the equation much simpler (as some of the coefficients will be 0)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "lasso_cv_model = LassoCV(eps=0.1, n_alphas=100, cv=5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "lasso_cv_model.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "LassoCV(cv=5, eps=0.1)"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "lasso_cv_model.alpha_"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4943070909225828"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "y_hat = ridge_model.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, y_hat))\n",
    "RMSE"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.8946386461319685"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "lasso_cv_model.coef_ # Notice how only 2 parameters have non-zero coefficients,\n",
    "# making the model much simpler"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1.002651  , 0.        , 0.        , 0.        , 3.79745279,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Elastic Net\n",
    "* Combination of L1 and L2\n",
    "* Total Error = Difference + µ|ß| + µß^2\n",
    "\n",
    "DIRECTLY USE ELASTIC NET INSTEAD OF L1 and L2 AS IT IS COMBINATION OF BOTH.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "elastic_model = ElasticNetCV(l1_ratio=[0.1,  0.5, 0.7, 0.9, 0.95, 0.99, 1], \n",
    "    eps=0.001, n_alphas=100, max_iter=1000000)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "elastic_model.fit(X_train, y_train)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "ElasticNetCV(l1_ratio=[0.1, 0.5, 0.7, 0.9, 0.95, 0.99, 1], max_iter=1000000)"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "elastic_model.l1_ratio_ # 1 -> Lasso Regression, 0 -> Ridge Regression"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "test_predictions = elastic_model.predict(X_test)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "RMSE = np.sqrt(mean_squared_error(y_test, test_predictions))\n",
    "RMSE"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.6063140748984036"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.5 64-bit ('MachineLearning': conda)"
  },
  "interpreter": {
   "hash": "4f2b92610986dfdf1303db89efd38395c6e139d83d56f94d766bf233b86e9dd0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}